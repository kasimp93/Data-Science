{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-506 HW 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting product star ratings \n",
    "## Using the Amazon Fine Food Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Time</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130058</td>\n",
       "      <td>B000CQIDHY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A worthy and welcome replacement</td>\n",
       "      <td>I don't know what has happened to formulation ...</td>\n",
       "      <td>1337817600</td>\n",
       "      <td>A3VZR9TPF2GERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91622</td>\n",
       "      <td>B004YV80OE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It was okay, good flavor</td>\n",
       "      <td>Kraft's a safe brand. They will produce food f...</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>A1B1QMGK8VYG80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>699</td>\n",
       "      <td>B000G6MBX2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The \"Organic\" Label is Misleading</td>\n",
       "      <td>\"Yeast Extract\" is listed as an ingredient. So...</td>\n",
       "      <td>1195084800</td>\n",
       "      <td>A1AQ2W2R4SOVGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265935</td>\n",
       "      <td>B0001GDC4O</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fresh/Stale</td>\n",
       "      <td>Some of these espresso pods were fresh and som...</td>\n",
       "      <td>1272499200</td>\n",
       "      <td>A2IVH1D3GLACL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199932</td>\n",
       "      <td>B000EDG430</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Baked to perfection in my bread machine!</td>\n",
       "      <td>I am not one to write reviews, but this bread ...</td>\n",
       "      <td>1336953600</td>\n",
       "      <td>AEOINN8F4D9DQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HelpfulnessDenominator  HelpfulnessNumerator      Id   ProductId  Score  \\\n",
       "0                       0                     0  130058  B000CQIDHY    5.0   \n",
       "1                       0                     0   91622  B004YV80OE    4.0   \n",
       "2                      10                     6     699  B000G6MBX2    1.0   \n",
       "3                       0                     0  265935  B0001GDC4O    5.0   \n",
       "4                       1                     1  199932  B000EDG430    5.0   \n",
       "\n",
       "                                    Summary  \\\n",
       "0          A worthy and welcome replacement   \n",
       "1                  It was okay, good flavor   \n",
       "2         The \"Organic\" Label is Misleading   \n",
       "3                               Fresh/Stale   \n",
       "4  Baked to perfection in my bread machine!   \n",
       "\n",
       "                                                Text        Time  \\\n",
       "0  I don't know what has happened to formulation ...  1337817600   \n",
       "1  Kraft's a safe brand. They will produce food f...  1317254400   \n",
       "2  \"Yeast Extract\" is listed as an ingredient. So...  1195084800   \n",
       "3  Some of these espresso pods were fresh and som...  1272499200   \n",
       "4  I am not one to write reviews, but this bread ...  1336953600   \n",
       "\n",
       "           UserId  \n",
       "0  A3VZR9TPF2GERB  \n",
       "1  A1B1QMGK8VYG80  \n",
       "2  A1AQ2W2R4SOVGN  \n",
       "3  A2IVH1D3GLACL3  \n",
       "4   AEOINN8F4D9DQ  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Training Data\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df.iloc[0:460804,:]\n",
    "#df = df.dropna()\n",
    "df = df.fillna(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Time</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460804</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>413937</td>\n",
       "      <td>B0029ZAOW8</td>\n",
       "      <td>Hated it!</td>\n",
       "      <td>I tried this product twice and both times it g...</td>\n",
       "      <td>1346630400</td>\n",
       "      <td>A3PHTRJUIW2C4J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460805</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16525</td>\n",
       "      <td>B001LGGH40</td>\n",
       "      <td>Tastes more like Carbonated apple juice</td>\n",
       "      <td>The ingredients on this item show several natu...</td>\n",
       "      <td>1237161600</td>\n",
       "      <td>A2R1HAXRNU0QX7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460806</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>221883</td>\n",
       "      <td>B001LNTY70</td>\n",
       "      <td>Great taste</td>\n",
       "      <td>Love the taste not to hot but a little tangy. ...</td>\n",
       "      <td>1211500800</td>\n",
       "      <td>A1VEOWIH3D0PTZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460807</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82207</td>\n",
       "      <td>B005ZBZLT4</td>\n",
       "      <td>Excellent Coffee!!!</td>\n",
       "      <td>Really, really good coffee!  A bold flavor wit...</td>\n",
       "      <td>1350000000</td>\n",
       "      <td>A6YOK7GISHUQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460808</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8354</td>\n",
       "      <td>B003VXFK44</td>\n",
       "      <td>great coffee</td>\n",
       "      <td>the aroma is awesome!!  love the flavor, reall...</td>\n",
       "      <td>1327708800</td>\n",
       "      <td>A2NPYVLJ7XPKS3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HelpfulnessDenominator  HelpfulnessNumerator      Id   ProductId  \\\n",
       "460804                       2                     0  413937  B0029ZAOW8   \n",
       "460805                       0                     0   16525  B001LGGH40   \n",
       "460806                       1                     1  221883  B001LNTY70   \n",
       "460807                       0                     0   82207  B005ZBZLT4   \n",
       "460808                       0                     0    8354  B003VXFK44   \n",
       "\n",
       "                                        Summary  \\\n",
       "460804                                Hated it!   \n",
       "460805  Tastes more like Carbonated apple juice   \n",
       "460806                              Great taste   \n",
       "460807                      Excellent Coffee!!!   \n",
       "460808                             great coffee   \n",
       "\n",
       "                                                     Text        Time  \\\n",
       "460804  I tried this product twice and both times it g...  1346630400   \n",
       "460805  The ingredients on this item show several natu...  1237161600   \n",
       "460806  Love the taste not to hot but a little tangy. ...  1211500800   \n",
       "460807  Really, really good coffee!  A bold flavor wit...  1350000000   \n",
       "460808  the aroma is awesome!!  love the flavor, reall...  1327708800   \n",
       "\n",
       "                UserId  \n",
       "460804  A3PHTRJUIW2C4J  \n",
       "460805  A2R1HAXRNU0QX7  \n",
       "460806  A1VEOWIH3D0PTZ  \n",
       "460807   A6YOK7GISHUQQ  \n",
       "460808  A2NPYVLJ7XPKS3  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Testing Data\n",
    "Data_test = pd.read_csv('train.csv')\n",
    "Data_test = Data_test.iloc[460804:560804,:]\n",
    "df_test = Data_test[['HelpfulnessDenominator','HelpfulnessNumerator', 'Id', 'ProductId', 'Summary', 'Text', 'Time', 'UserId']]\n",
    "#df_test = df_test.dropna()\n",
    "df_test = df_test.fillna(\"\")\n",
    "test_labels = df_test['Id']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A worthy and welcome replacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>It was okay, good flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The \"Organic\" Label is Misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Fresh/Stale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Baked to perfection in my bread machine!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                   Summary\n",
       "0    5.0          A worthy and welcome replacement\n",
       "1    4.0                  It was okay, good flavor\n",
       "2    1.0         The \"Organic\" Label is Misleading\n",
       "3    5.0                               Fresh/Stale\n",
       "4    5.0  Baked to perfection in my bread machine!"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data\n",
    "Data = df[['HelpfulnessDenominator','HelpfulnessNumerator', 'Id', 'ProductId', 'Summary', 'Text', 'Time', 'UserId']]\n",
    "Data.head()\n",
    "\n",
    "Data_pre = df[['Score', 'Summary']]\n",
    "Data_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460804,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Labels\n",
    "Y_data = df['Score']\n",
    "Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "translation = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "\n",
    "def preprocessing(line):\n",
    "    tokens=[]\n",
    "    line = line.translate(translation)\n",
    "    line = nltk.word_tokenize(line.lower())\n",
    "    for t in line:\n",
    "        stemmed = lemmatizer.lemmatize(t)\n",
    "        tokens.append(stemmed)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_lem_1 = []\n",
    "data_lem_2 = []\n",
    "for p in Data['Summary']:\n",
    "    data_lem_1.append(preprocessing(p))\n",
    "\n",
    "for p in Data['Text']:\n",
    "    data_lem_2.append(preprocessing(p))\n",
    "\n",
    "data_lem = data_lem_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460804"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_lem_test_1 = []\n",
    "data_lem_test_2 = []\n",
    "for p in df_test['Summary']:\n",
    "    data_lem_test_1.append(preprocessing(p))\n",
    "\n",
    "for p in df_test['Text']:\n",
    "    data_lem_test_2.append(preprocessing(p))\n",
    "    \n",
    "data_lem_test = data_lem_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Normalizer\n",
    "# f_1 = Data['HelpfulnessDenominator'].tolist()\n",
    "# f_2 = Data['HelpfulnessNumerator'].tolist()\n",
    "# f_1 = np.asarray(f_1)\n",
    "# f_2 = np.asarray(f_2)\n",
    "# centered_f = Normalizer(copy=False).fit_transform(np.column_stack((f_1, f_2)))\n",
    "# data_lem_1 = np.array(list(data_lem))\n",
    "# dtm_final = np.column_stack((data_lem_1, centered_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460804, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Normalizer\n",
    "# f_11 = df_test['HelpfulnessDenominator'].tolist()\n",
    "# f_22 = df_test['HelpfulnessNumerator'].tolist()\n",
    "# f_11 = np.asarray(f_11)\n",
    "# f_22 = np.asarray(f_22)\n",
    "# centered_f2 = Normalizer(copy=False).fit_transform(np.column_stack((f_11, f_22)))\n",
    "# data_lem_test_1 = np.array(list(data_lem_test))\n",
    "# dtm_final_test = np.column_stack((data_lem_test_1, centered_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data into testing and training\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_lem, Y_data, test_size=0.0001, random_state=20160121, stratify = Y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for line in X_train:\n",
    "    l = nltk.word_tokenize(line)\n",
    "    for w in l:\n",
    "        t.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test data\n",
    "t_test = []\n",
    "for line in data_lem_test:\n",
    "    l_test = nltk.word_tokenize(line)\n",
    "    for w in l_test:\n",
    "        t_test.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923567"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28135\n"
     ]
    }
   ],
   "source": [
    "word_features = nltk.FreqDist(t)\n",
    "print (len(word_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14420\n"
     ]
    }
   ],
   "source": [
    "word_features_final = nltk.FreqDist(t_test)\n",
    "print (len(word_features_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vec_all = CountVectorizer()\n",
    "ctr_features_all = vec_all.fit_transform(data_lem)\n",
    "\n",
    "\n",
    "tf_vec_all = TfidfTransformer()\n",
    "tr_features_all = tf_vec_all.fit_transform(ctr_features_all)\n",
    "\n",
    "cte_features_all = vec_all.transform(X_test)\n",
    "te_features_all = tf_vec_all.transform(cte_features_all)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "tr_features_truncated = svd.fit_transform(tr_features_all)\n",
    "\n",
    "te_features_truncated = svd.transform(te_features_all)\n",
    "\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "ctr_features_truncated = svd.fit_transform(ctr_features_all)\n",
    "cte_features_truncated = svd.transform(cte_features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_all_final = CountVectorizer()\n",
    "ctr_features_all_final = vec_all_final.fit_transform(data_lem_test)\n",
    "\n",
    "\n",
    "tf_vec_all_final = TfidfTransformer()\n",
    "tr_features_all_final = tf_vec_all_final.fit_transform(ctr_features_all_final)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_final = TruncatedSVD(n_components=50)\n",
    "tr_features_truncated_final = svd_final.fit_transform(tr_features_all_final)\n",
    "\n",
    "svd_final_1 = TruncatedSVD(n_components=50)\n",
    "ctr_features_truncated_final = svd_final_1.fit_transform(ctr_features_all_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23040200"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_features_truncated.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Normalizer\n",
    "# f_1 = Data['HelpfulnessDenominator'].tolist()\n",
    "# f_2 = Data['HelpfulnessNumerator'].tolist()\n",
    "# f_1 = np.asarray(f_1)\n",
    "# f_2 = np.asarray(f_2)\n",
    "# centered_f = Normalizer(copy=False).fit_transform(np.column_stack((f_1, f_2)))\n",
    "# tr_features_truncated_1 = np.array(list(tr_features_truncated))\n",
    "# dtm_final = np.column_stack((tr_features_truncated, centered_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = sm.OLS(y_train, tr_features_truncated)\n",
    "# results = model.fit()\n",
    "# print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# y_predict = results.predict(te_features_truncated)\n",
    "# MSE_test = mean_squared_error(y_test, y_predict)\n",
    "# print(\"Mean Square Error is\", MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_1 = Ridge(alpha=2)\n",
    "# results_1 = model_1.fit(tr_features_truncated, y_train) \n",
    "# y_predict_1 = results_1.predict(te_features_truncated)\n",
    "# MSE_test_1 = mean_squared_error(y_test, y_predict_1)\n",
    "# print(\"Mean Square Error is\", MSE_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model_2 = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "# results_2 = model_2.fit(tr_features_truncated, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tr_features_truncated = scale(tr_features_truncated)\n",
    "# tr_features_truncated_final = scale(tr_features_truncated_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 50)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_features_truncated_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error is 1.28730824342\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# model_n = MLPRegressor(hidden_layer_sizes=(20,10), alpha=1,max_iter=20000)\n",
    "# results_n = model_n.fit(tr_features_truncated, Y_data)\n",
    "# y_predict_final = results_n.predict(tr_features_truncated)\n",
    "# MSE_train = mean_squared_error(Y_data, y_predict_final)\n",
    "# print(\"Mean Square Error is\", MSE_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# model_n = MLPClassifier(solver = 'sgd', alpha = 1, nesterovs_momentum = True )\n",
    "# results_n = model_n.fit(tr_features_truncated, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error is 2.09686981884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_n = SVC(kernel= 'linear', C=1.0)\n",
    "results_n = model_n.fit(tr_features_truncated, Y_data)\n",
    "y_predict_final = results_n.predict(tr_features_truncated)\n",
    "MSE_train = mean_squared_error(Y_data, y_predict_final)\n",
    "print(\"Mean Square Error is\", MSE_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_final = results_n.predict(tr_features_truncated_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in y_predict_final:\n",
    "    res.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(res)):\n",
    "    if(res[i] > 5):\n",
    "        res[i] = 5\n",
    "        \n",
    "res = [int(round(i,)) for i in res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_1 =[]\n",
    "test_labels_1 = test_labels.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Id','Score'])\n",
    "with open('submission.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    for i in range(100000):\n",
    "        writer = csv.writer(csvfile)    \n",
    "        writer.writerow([test_labels_1[i], res[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
